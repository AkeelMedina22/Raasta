import os
import numpy as np
import tensorflow as tf
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pylab as plt
import matplotlib.pyplot as plt
import numpy as np
from newdata import get_data
import matplotlib.pyplot as plt
import numpy as np
# cnn model
from numpy import dstack
from pandas import read_csv
from keras.layers import Dense
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
import tensorflow_addons as tfa
from keras.utils import to_categorical
from scipy import signal
from scipy.interpolate import splev, splrep
import os
import seaborn as sns
sns.set()
import folium
from sklearn.model_selection import KFold
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
import synthia as syn
def resample(data, old_fs, new_fs=2):
    t = np.arange(len(data)) / old_fs
    spl = splrep(t, data)
    t1 = np.arange((len(data))*new_fs) / (old_fs*new_fs)
    return splev(t1, spl)

def train_test_split(data):

    window = []
    window_loc = []
    window_size = 60
    stride = 30
    p_count = 0
    s_count = 0
    n_count = 0

    assert len(data) > 2*window_size + 1
    count = 0
    for i in range(0, len(data)-window_size, stride):
        
        temp = data[i:i+window_size]
        without_labels = [[i[0][0], i[0][1], i[0][2]] for i in temp]
        potholes, normalroads, speedbreakers = 0, 0, 0
        for j in temp:
            if j[1] == "Pothole" or j[1] == "Bad Road":
                potholes += 1
            elif j[1] == "Normal Road":
                normalroads += 1
            elif j[1] == "Speedbreaker":
                speedbreakers += 1
        dic = {"potholes" : potholes, "normal roads": normalroads, "speedbreakers": speedbreakers}
      

        if dic["potholes"] >= 1:
            window.append([without_labels, 'Pothole'])
            p_count+=1
        elif dic['speedbreakers'] >= 1:
            window.append([without_labels, 'Speedbreakers'])
            s_count += 1
        elif dic['normal roads'] >= 1:
            window.append([without_labels, 'Normal road'])
            n_count += 1
        else:
            continue

    def augment(window, n):
        potholes = []
        normals = []
        speedbreakers = []
        new_window = []
        countt = 0
        for j in range(len(window)):
            if window[j][1] == "Pothole" or window[j][1] == "Bad road":
                potholes.append(window[j][0])
                new_window.append(window[j])

            elif window[j][1] == "Normal road":
                normals.append(window[j][0])
                new_window.append(window[j])

            elif window[j][1] == "Speedbreakers" and countt < 20:
                speedbreakers.append(window[j][0])
                new_window.append(window[j])
                # countt += 1

        count = 0
        # for data in [potholes, normals, bads, speedbreakers]:
        #     synthetic = []
        #     data = np.array(data).transpose(2, 0, 1)
        #     for i in range(6):
        #         generator = syn.CopulaDataGenerator()     
        #         parameterizer = syn.QuantileParameterizer(n_quantiles=100)   
        #         generator.fit(data[i], copula=syn.GaussianCopula(), parameterize_by=parameterizer)  
        #         samples = generator.generate(n_samples=400)   
        #         synthetic.append(samples)
        #     synthetic = np.array(synthetic).transpose(1,2,0)
        #     if count == 0:
        #         for i in synthetic:
        #             new_window.append([i, 'Pothole'])
        #     elif count == 1:
        #         for i in synthetic:
        #             new_window.append([i, 'Normal road'])
        #     elif count == 2:
        #         for i in synthetic:
        #             new_window.append([i, 'Bad road'])
        #     elif count == 3:
        #         for i in synthetic:
        #             new_window.append([i, 'Speedbreakers'])
        #     count += 1 

        fig, axs = plt.subplots(2)
        for data in [speedbreakers]:
            data = np.array(data)
            data = np.array([np.concatenate((data[i][:,0],data[i][:,1],data[i][:,2])) for i in range(data.shape[0])])
            for i in range(data.shape[0]):
                axs[0].plot(range(60*3), data[i], alpha=0.1, color='tab:blue')
                axs[0].set_title("Training Data", fontfamily='roboto')
            generator = syn.FPCADataGenerator()      
            generator.fit(data, n_fpca_components=150)   
            samples = generator.generate(n_samples=len(data))   
            synthetic = np.array(samples)
            if count == 0:
                for j in synthetic:
                    axs[1].plot(range(60*3), j, alpha=0.1, color='tab:blue')
                    axs[1].set_title("Synthethic Data generated by fPCA", fontfamily='roboto')
                    j = np.array((j[0:60], j[60:120], j[120:180])).T
                    new_window.append([j, 'Pothole'])
        
        return new_window


    print((p_count, s_count, n_count))

    # window = augment(window)

    data = np.array(window, dtype=object)

    data = data[np.random.permutation(len(data))]

    train_ratio = 0.85
    sequence_len = data.shape[0]

    train_data = np.array(augment(data[0:int(sequence_len*train_ratio)], 900), dtype=object)
    # test_data = np.array(augment(data[int(sequence_len*train_ratio):], 200), dtype=object)
    plt.tight_layout()
    plt.show()
    return train_data


data, longitude, latitude = get_data()
train_data= train_test_split(data)